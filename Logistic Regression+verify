###逻辑回归Logistic Regression###
#数据准备
data1 <- read.csv("/mnt/raid5/User/bailin/project/240909Carotid.plaque/data/GSE43292/preprocessing/exp_norm.csv",row.names = 1)
intersection <- read.csv("/mnt/raid5/User/bailin/project/240909Carotid.plaque/result/DEG+enrichment/intersection_genes.csv",row.names = 1)
data <- data1[intersection$x,]
head(data)
sample_names <- colnames(data)
# 提取样本名的最后一位
last_digits <- as.numeric(substr(sample_names, nchar(sample_names), nchar(sample_names)))
# 判断奇偶数，奇数为 normal (0)，偶数为 case (1)
labels <- ifelse(last_digits %% 2 == 0, 1, 0)  # 偶数为 case (1), 奇数为 normal (0)
data_t <- t(data)
# 转换为数据框并添加标签列
data_t <- as.data.frame(data_t)
data_t$label <- labels
head(data_t)

library(caTools)
set.seed(123)
# 拆分数据集，80% 用于训练，20% 用于测试
split <- sample.split(data_t$label, SplitRatio = 0.8)
train_data <- subset(data_t, split == TRUE)
test_data <- subset(data_t, split == FALSE)
# 分离训练集和测试集中的特征（X）和标签（y）
# 分离训练集和测试集中的特征（X）和标签（y）
X_train <- train_data[, -ncol(train_data)]  # 移除最后一列标签列 (label)
y_train <- train_data$label
X_test <- test_data[, -ncol(test_data)]     # 同样移除标签列
y_test <- test_data$label
head(X_train)
head(y_train)
# 使用训练集训练逻辑回归模型
model <- glm(y_train ~ ., data = train_data[, -ncol(train_data)], family = "binomial")
saveRDS(model, file = "logistic_model.rds")
# 查看模型摘要
summary(model)
# 使用训练好的模型进行预测
predictions_prob <- predict(model, newdata = X_test, type = "response")
# 将概率转化为二分类结果
predictions <- ifelse(predictions_prob > 0.5, 1, 0)
# 查看预测结果
head(predictions)

# 提取回归系数和置信区间
coef <- summary(model)$coefficients  
conf_int <- confint(model)          
exp_coef <- exp(coef[, 1])          
lower_ci <- exp(conf_int[, 1])       
upper_ci <- exp(conf_int[, 2])      
p_values <- coef[, 4]  
forest_data <- data.frame(
  Variable = rownames(coef),   
  Estimate = exp_coef,       
  LowerCI = lower_ci,          
  UpperCI = upper_ci,           
  P.value = p_values           
)
print(forest_data)
write.csv(forest_data,"/mnt/raid5/User/bailin/project/240909Carotid.plaque/result/Logistic Regression/forest_data.csv")
# 格式化 OR 和 p 值
forest_data$OR <- format(round(forest_data$Estimate, 2), nsmall = 2)
forest_data$P.value <- formatC(forest_data$P.value, format = "e", digits = 2)
# 构建标签矩阵，包括变量、OR 值和 p 值
labeltext <- cbind(
  Variable = forest_data$Variable,
  OR = forest_data$OR,           # OR 值
  P.value = forest_data$P.value  # p 值
)
#绘制森林图
library(forestplot)
pdf(file = "forest.pdf", width = 12, height = 6)
forestplot(
  labeltext = labeltext,                   # 标签文字 (变量, OR, P值)
  mean = forest_data$Estimate,             # 中心点（OR值）
  lower = forest_data$LowerCI,             # 置信区间下限
  upper = forest_data$UpperCI,             # 置信区间上限
  zero = 1,                                # 参考线位置设为 1 （用于OR）
  boxsize = 0.3,                           # 盒子的大小
  lineheight = unit(8, 'mm'),              # 行高调整
  colgap = unit(3, 'mm'),                  # 列间距
  lwd.zero = 2,                            # 参考线的宽度
  lwd.ci = 2.5,                            # 置信区间线的宽度
  col = fpColors(
    box = '#228B22',                       # 盒子颜色（绿色）
    lines = 'black',                       # 线条颜色
    zero = '#2E8B57'                       # 参考线颜色
  ),
  xlab = "Odds Ratio (OR)",                # X轴标签
  lwd.xaxis = 1.5,                         # X轴线宽度
  txt_gp = fpTxtGp(
    ticks = gpar(cex = 0.9),               # 刻度文字大小
    xlab = gpar(cex = 0.9),                # X轴标签大小
    label = gpar(cex = 1)                  # 标签文字大小
  ),
  lty.ci = "solid",                        # 置信区间线类型
  ci.vertices = TRUE,                      # 添加置信区间的端点
  ci.vertices.height = 0.1,                # 置信区间端点高度
  title = "Forest Plot of Odds Ratios",    # 图形标题
  graph.pos = 2                            # 图形在标签的右侧
)
dev.off()

#模型评估
#1.混淆矩阵评估
library(caret)
conf_matrix <- confusionMatrix(factor(predictions), factor(y_test))
# 假设 y_test 是实际的标签，predictions 是模型预测的类别
# 计算混淆矩阵
conf_matrix <- confusionMatrix(factor(predictions), factor(y_test))
print(conf_matrix)
conf_matrix_df <- as.data.frame(conf_matrix$table)
write.csv(conf_matrix_df, file = "confusion_matrix.csv", row.names = FALSE)
# 打印混淆矩阵的统计指标，例如Accuracy、Sensitivity、Specificity等
stats_df <- as.data.frame(t(conf_matrix$overall))
write.csv(stats_df, file = "confusion_matrix_stats.csv", row.names = FALSE)
# 可选：也可以保存分类统计，例如敏感性和特异性
class_stats_df <- as.data.frame(t(conf_matrix$byClass))
write.csv(class_stats_df, file = "class_stats.csv", row.names = FALSE)

#2.生成ROC曲线并计算AUC值
library(pROC)
roc_curve <- roc(y_test, predictions_prob)
pdf(file = "ROC.pdf", width = 6, height = 6)
# 加载pROC包
library(pROC)
roc_curve <- roc(y_test, predictions_prob)
auc_value <- auc(roc_curve)
# 绘制ROC曲线
pdf(file = "ROC.pdf", width = 6, height = 6)
plot(roc_curve, col = "blue", lwd = 2, main = "ROC Curve with AUC")
# 在图中标注AUC值
text(0.6, 0.4, paste("AUC =", round(auc_value, 3)), col = "red", cex = 1.2)
# 可选择增加轴标签等
xlabel <- "False Positive Rate (1 - Specificity)"
ylabel <- "True Positive Rate (Sensitivity)"
title(main = "ROC Curve", sub = "Blue: ROC curve, Red: AUC")
# 显示网格线
grid()
dev.off()

###external verify###
rm(list = ls())
setwd("/mnt/raid5/User/bailin/project/240909Carotid.plaque/result/verify/")
#构建特征矩阵
model <- readRDS("/mnt/raid5/User/bailin/project/240909Carotid.plaque/result/Logistic Regression/logistic_model.rds")
summary(model)
gene <- c("TPH1","MAOB","TDO2","KMO","KYNU","CYP1B1")
data <- read.csv("/mnt/raid5/User/bailin/project/240909Carotid.plaque/data/GSE100927/exp_symbol_avg_sample.csv",row.names = 1)
X_test_external <- data[gene,]
#构建真实标签
cli <- read.csv("/mnt/raid5/User/bailin/project/240909Carotid.plaque/data/GSE100927/cli.csv",row.names = 1)
cli_data <- cli[grep("Control carotid artery|Atherosclerotic carotid artery", cli$tissue), ]
table(cli_data$tissue)
unique(cli_data$tissue)
cli_data$label <- ifelse(cli_data$tissue == "Control carotid artery", 0,
                         ifelse(cli_data$tissue == "Atherosclerotic carotid artery", 1, NA))
head(cli_data[, c("tissue", "label")])
y_test_external <- cli_data$label
head(X_test_external)  # 查看外部特征矩阵
head(y_test_external)  # 查看外部真实标签
